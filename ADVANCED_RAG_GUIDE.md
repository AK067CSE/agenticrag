# Advanced RAG System Guide

## Overview

This system implements an **advanced hybrid RAG (Retrieval-Augmented Generation)** approach with:

- âœ… **Pre-processing**: PDF is chunked and indexed **once** before runtime
- âœ… **Dense Retrieval**: Semantic vector search using FastEmbed (BAAI/bge-base-en-v1.5)
- âœ… **Sparse Retrieval**: Keyword-based BM25 search
- âœ… **Hybrid Retrieval**: Combines dense + sparse for optimal results
- âœ… **Fast Runtime**: No ingestion delays, only retrieval operations
- âœ… **Scalable**: Easy to add new PDFs or update existing ones

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OFFLINE (Run Once)                        â”‚
â”‚                                                              â”‚
â”‚  nephrology.pdf â†’ ingest_advanced.py â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                         â”‚  Dense Index  â”‚   â”‚
â”‚                                         â”‚  (ChromaDB)   â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                         â”‚  Sparse Index â”‚   â”‚
â”‚                                         â”‚  (BM25)       â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                         â”‚  Chunks JSON  â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ONLINE (Runtime)                          â”‚
â”‚                                                              â”‚
â”‚  User Query â†’ Clinical Agent â†’ RAG Engine                   â”‚
â”‚                                     â”‚                        â”‚
â”‚                                     â”œâ†’ Dense Search          â”‚
â”‚                                     â”œâ†’ Sparse Search         â”‚
â”‚                                     â””â†’ Hybrid Fusion         â”‚
â”‚                                                              â”‚
â”‚                                     â†“                        â”‚
â”‚                               Top-K Results                  â”‚
â”‚                                     â†“                        â”‚
â”‚                            Gemini LLM + Context             â”‚
â”‚                                     â†“                        â”‚
â”‚                              Final Answer                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Setup Instructions

### Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

This will install:
- `fastembed` - Fast CPU-based embeddings
- `chromadb` - Dense vector store
- `rank-bm25` - Sparse BM25 retrieval
- All other required packages

### Step 2: One-Time Ingestion

Run the ingestion script **once** to process your PDF:

```bash
python ingest_advanced.py
```

**What this does:**
1. Loads `../data/nephrology.pdf`
2. Splits it into chunks (1000 chars, 200 overlap)
3. Creates dense vector index (ChromaDB)
4. Creates sparse BM25 index
5. Saves chunks as JSON

**Output:**
```
ğŸ“– Loading PDF from ...
âœ… Loaded 425 pages
âœ‚ï¸  Chunking document...
âœ… Created 1847 chunks
ğŸ’¾ Saving chunks to ...
âœ… Saved 1847 chunks
ğŸ”¢ Building dense vector index (ChromaDB)...
âœ… Dense index built with 1847 vectors
ğŸ“Š Building sparse BM25 index...
âœ… BM25 index built and saved
================================================================================
âœ… Ingestion Complete!
   - Chunks: data/processed/chunks.json
   - Dense Index: chroma_db/
   - Sparse Index: data/processed/bm25_index.pkl
================================================================================
```

### Step 3: Run the Application

```bash
streamlit run app.py
```

The app now starts **instantly** - no ingestion delays!

## Retrieval Methods

The system supports three retrieval methods:

### 1. Dense Retrieval (Semantic)
Uses vector embeddings to find semantically similar content.

**Best for:** Conceptual queries, paraphrasing

```python
results = rag_engine.retrieve(query, k=5, method="dense")
```

### 2. Sparse Retrieval (Keyword/BM25)
Uses term frequency and inverse document frequency.

**Best for:** Specific terms, exact matches, medical terminology

```python
results = rag_engine.retrieve(query, k=5, method="sparse")
```

### 3. Hybrid Retrieval (Recommended)
Combines dense + sparse with weighted fusion.

**Best for:** General use, balanced results

```python
results = rag_engine.retrieve(query, k=5, method="hybrid")
```

**Default weights:**
- Dense: 70% (semantic similarity)
- Sparse: 30% (keyword matching)

## Adding New PDFs

To index a new PDF or update an existing one:

```bash
# Edit ingest_advanced.py to point to your PDF
# Then run:
python ingest_advanced.py
```

The ingestion script will:
1. Delete old indexes
2. Re-chunk and re-index the PDF
3. Save new indexes

The Streamlit app will automatically use the new indexes on next query.

## Performance Benchmarks

### Ingestion (One-Time)
- **88MB PDF**: ~30 seconds
- **Creates**: 1800+ chunks, 3 indexes

### Runtime (Per Query)
- **Cold start**: ~2 seconds (first query, loads indexes)
- **Warm queries**: <500ms (subsequent queries)
- **Hybrid retrieval**: +100ms vs single method

### Memory Usage
- **Indexes on disk**: ~200MB
- **Loaded in RAM**: ~150MB
- **Per query**: <10MB

## Advanced Configuration

### Tuning Retrieval

Edit `rag_engine_advanced.py`:

```python
# Adjust weights for hybrid retrieval
DENSE_WEIGHT = 0.7   # Higher = more semantic
SPARSE_WEIGHT = 0.3  # Higher = more keyword-focused

# Adjust similarity threshold
SIMILARITY_THRESHOLD = 0.3  # Lower = more permissive
```

### Tuning Chunking

Edit `ingest_advanced.py`:

```python
CHUNK_SIZE = 1000      # Smaller = more precise, more chunks
CHUNK_OVERLAP = 200    # Higher = more context, more storage
```

**Guidelines:**
- Medical docs: 1000-1500 chars
- Technical docs: 500-1000 chars
- General text: 1500-2000 chars

## Retrieval Quality

### Citations
Every retrieved chunk includes:
- Source document name
- Page number
- Relevance score (0-1)
- Retrieval method used

Example:
```
[Source 1 - Page 42, Relevance: 0.847, Method: hybrid]
Chronic kidney disease (CKD) is defined as...
```

### Relevance Scoring
- **Dense**: Cosine similarity (higher = more similar)
- **Sparse**: BM25 score (normalized 0-1)
- **Hybrid**: Weighted combination

### Fallback Strategy
1. Try hybrid retrieval
2. If no results above threshold â†’ Web search
3. Always cite sources

## Troubleshooting

### Error: "Vector DB not found"
**Solution:** Run `python ingest_advanced.py`

### Error: "rank-bm25 not installed"
**Solution:** `pip install rank-bm25`

### Slow retrieval
**Possible causes:**
- First query (loading indexes)
- Too many chunks (>5000)
- Old hardware

**Solutions:**
- Increase chunk size
- Use only dense retrieval
- Reduce top-k

### Poor results
**Try:**
1. Adjust hybrid weights
2. Lower similarity threshold
3. Increase top-k
4. Re-chunk with different parameters

## File Structure

```
fresh_system/
â”œâ”€â”€ ingest_advanced.py          # One-time ingestion script
â”œâ”€â”€ rag_engine_advanced.py      # Hybrid retrieval engine
â”œâ”€â”€ clinical_agent.py           # Updated to use advanced RAG
â”œâ”€â”€ app.py                      # Streamlit frontend
â”‚
â”œâ”€â”€ chroma_db/                  # Dense vector index (auto-created)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ chunks.json         # Pre-processed chunks
â”‚       â””â”€â”€ bm25_index.pkl      # Sparse index
â”‚
â””â”€â”€ requirements.txt            # All dependencies
```

## API Reference

### `HybridRAGEngine`

```python
from rag_engine_advanced import get_rag_engine

engine = get_rag_engine()  # Singleton instance

# Retrieve documents
results = engine.retrieve(
    query="What is CKD?",
    k=5,
    method="hybrid"  # or "dense", "sparse"
)

# Get formatted context
context = engine.get_context_for_query(
    query="What is CKD?",
    k=5,
    method="hybrid"
)

# Check if relevant info exists
has_info = engine.has_relevant_information(
    query="What is CKD?",
    threshold=0.3,
    method="hybrid"
)
```

### Backward Compatibility

Old code still works:

```python
from rag_engine_advanced import (
    retrieve_relevant_docs,
    get_context_for_query,
    has_relevant_information
)

docs = retrieve_relevant_docs("What is CKD?", k=5)
context = get_context_for_query("What is CKD?", k=5)
has_info = has_relevant_information("What is CKD?")
```

## Best Practices

1. **Always ingest offline** - Never chunk/embed at runtime
2. **Use hybrid retrieval** - Best balance of precision/recall
3. **Set appropriate k** - 3-5 for focused, 5-10 for broad
4. **Monitor relevance scores** - Below 0.3 = fallback to web
5. **Update indexes regularly** - When PDF content changes
6. **Cite sources** - Always show where information comes from

## Next Steps

- âœ… System is production-ready
- âœ… Fast retrieval (<500ms)
- âœ… Hybrid search implemented
- âœ… Citations included
- âœ… Easy to update PDFs

To use:
1. `pip install -r requirements.txt`
2. `python ingest_advanced.py` (once)
3. `streamlit run app.py`
4. Chat away! ğŸš€
